{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing into file and integrating models\n",
    "\n",
    "In this tutorial, you will learn how to embed text classifiers, generative models and databases into your DialogFlow scripts. \n",
    "\n",
    "Specifically, we will write the bot that outputs answer from generative model when the classifier detects neutral sentiment, outputs the word \"positive\" when the classifier detects positive sentiment and outputs the word \"negative\" when the classifier detects negative sentiment\n",
    "\n",
    "First of all, you need to extract the prerequisites. Execute the commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: df_engine in /home/dimakarp1996/.local/lib/python3.8/site-packages (0.10.1)\n",
      "Requirement already satisfied: pydantic>=1.8.2 in /home/dimakarp1996/.local/lib/python3.8/site-packages (from df_engine) (1.9.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/dimakarp1996/.local/lib/python3.8/site-packages (from pydantic>=1.8.2->df_engine) (3.7.4.3)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: df_db_connector in /home/dimakarp1996/.local/lib/python3.8/site-packages (0.1.1)\n",
      "Requirement already satisfied: df-engine>=0.9.0 in /home/dimakarp1996/.local/lib/python3.8/site-packages (from df_db_connector) (0.10.1)\n",
      "Requirement already satisfied: pydantic>=1.8.2 in /home/dimakarp1996/.local/lib/python3.8/site-packages (from df-engine>=0.9.0->df_db_connector) (1.9.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/dimakarp1996/.local/lib/python3.8/site-packages (from pydantic>=1.8.2->df-engine>=0.9.0->df_db_connector) (3.7.4.3)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: tqdm==4.40.0 in /home/dimakarp1996/.local/lib/python3.8/site-packages (4.40.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: transformers==4.0.0 in /home/dimakarp1996/.local/lib/python3.8/site-packages (4.0.0)\n",
      "Requirement already satisfied: filelock in /home/dimakarp1996/.local/lib/python3.8/site-packages (from transformers==4.0.0) (3.0.12)\n",
      "Requirement already satisfied: numpy in /home/dimakarp1996/.local/lib/python3.8/site-packages (from transformers==4.0.0) (1.18.0)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers==4.0.0) (2.22.0)\n",
      "Requirement already satisfied: sacremoses in /home/dimakarp1996/.local/lib/python3.8/site-packages (from transformers==4.0.0) (0.0.35)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/dimakarp1996/.local/lib/python3.8/site-packages (from transformers==4.0.0) (4.40.0)\n",
      "Requirement already satisfied: tokenizers==0.9.4 in /home/dimakarp1996/.local/lib/python3.8/site-packages (from transformers==4.0.0) (0.9.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/dimakarp1996/.local/lib/python3.8/site-packages (from transformers==4.0.0) (2021.11.10)\n",
      "Requirement already satisfied: packaging in /home/dimakarp1996/.local/lib/python3.8/site-packages (from transformers==4.0.0) (21.3)\n",
      "Requirement already satisfied: joblib in /home/dimakarp1996/.local/lib/python3.8/site-packages (from sacremoses->transformers==4.0.0) (1.0.1)\n",
      "Requirement already satisfied: six in /home/dimakarp1996/.local/lib/python3.8/site-packages (from sacremoses->transformers==4.0.0) (1.15.0)\n",
      "Requirement already satisfied: click in /home/dimakarp1996/.local/lib/python3.8/site-packages (from sacremoses->transformers==4.0.0) (7.1.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/lib/python3/dist-packages (from packaging->transformers==4.0.0) (2.4.6)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: tensorflow-gpu==2.3 in /home/dimakarp1996/.local/lib/python3.8/site-packages (2.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /home/dimakarp1996/.local/lib/python3.8/site-packages (from tensorflow-gpu==2.3) (1.12.1)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /home/dimakarp1996/.local/lib/python3.8/site-packages (from tensorflow-gpu==2.3) (2.10.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/dimakarp1996/.local/lib/python3.8/site-packages (from tensorflow-gpu==2.3) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /home/dimakarp1996/.local/lib/python3.8/site-packages (from tensorflow-gpu==2.3) (2.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in /home/dimakarp1996/.local/lib/python3.8/site-packages (from tensorflow-gpu==2.3) (0.2.0)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /home/dimakarp1996/.local/lib/python3.8/site-packages (from tensorflow-gpu==2.3) (1.34.1)\n",
      "Requirement already satisfied: gast==0.3.3 in /home/dimakarp1996/.local/lib/python3.8/site-packages (from tensorflow-gpu==2.3) (0.3.3)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/dimakarp1996/.local/lib/python3.8/site-packages (from tensorflow-gpu==2.3) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /home/dimakarp1996/.local/lib/python3.8/site-packages (from tensorflow-gpu==2.3) (3.17.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /home/dimakarp1996/.local/lib/python3.8/site-packages (from tensorflow-gpu==2.3) (1.1.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /home/dimakarp1996/.local/lib/python3.8/site-packages (from tensorflow-gpu==2.3) (0.36.2)\n",
      "Requirement already satisfied: scipy==1.4.1 in /home/dimakarp1996/.local/lib/python3.8/site-packages (from tensorflow-gpu==2.3) (1.4.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/dimakarp1996/.local/lib/python3.8/site-packages (from tensorflow-gpu==2.3) (1.15.0)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in /home/dimakarp1996/.local/lib/python3.8/site-packages (from tensorflow-gpu==2.3) (2.9.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /home/dimakarp1996/.local/lib/python3.8/site-packages (from tensorflow-gpu==2.3) (0.12.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in /home/dimakarp1996/.local/lib/python3.8/site-packages (from tensorflow-gpu==2.3) (1.6.3)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /home/dimakarp1996/.local/lib/python3.8/site-packages (from tensorflow-gpu==2.3) (1.18.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/dimakarp1996/.local/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3) (1.30.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3) (2.22.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/dimakarp1996/.local/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/dimakarp1996/.local/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3) (1.8.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/dimakarp1996/.local/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3) (2.0.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /usr/lib/python3/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3) (45.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/dimakarp1996/.local/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/dimakarp1996/.local/lib/python3.8/site-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3) (0.4.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /home/dimakarp1996/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/dimakarp1996/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/dimakarp1996/.local/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/dimakarp1996/.local/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3) (1.3.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/dimakarp1996/.local/lib/python3.8/site-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<3,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install df_engine\n",
    "!pip install df_db_connector\n",
    "!pip install tqdm==4.40.0\n",
    "!pip install transformers==4.0.0\n",
    "!pip install tensorflow-gpu==2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL_PATH=........../convert_data/convert\n",
    "import os\n",
    "from df_engine.core.keywords import GLOBAL, TRANSITIONS, RESPONSE, MISC, LOCAL\n",
    "from df_engine.core.keywords import PRE_RESPONSE_PROCESSING, PRE_TRANSITIONS_PROCESSING\n",
    "from df_engine.core import Context, Actor\n",
    "import df_engine.conditions as cnd\n",
    "import df_engine.responses\n",
    "import df_engine.labels as lbl\n",
    "from df_engine.core.types import NodeLabel3Type\n",
    "from df_db_connector import connector_factory\n",
    "from typing import Union, Optional, Any\n",
    "from numpy import random\n",
    "import logging\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment detection\n",
    "\n",
    "For sentiment detection, we will use the pipelines from [huggingface](#https://huggingface.co/docs/transformers/v4.0.0/en/main_classes/pipelines) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline('sentiment-analysis')\n",
    "\n",
    "def get_sentiment(utterance):\n",
    "    print('get_sentiment '+(utterance))\n",
    "    return classifier(utterance)[0]['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using retrieval model to generate the response for the negative sentiment\n",
    "We use the [huggingface](#https://huggingface.co/) feature extraction model also to select the response for the negative sentiment.\n",
    "    \n",
    "Specifically, we will look for the response vector whose cosine similarity to the request vector is maximal. \n",
    "    \n",
    "For vectorization of response and request, we use the mean of the representation of every word obtained by the huggingface model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "retrieval = pipeline('feature-extraction')\n",
    "\n",
    "def get_representation(sentence):\n",
    "    ### We calculate the mean of representation of every word.\n",
    "    return np.array(retrieval([sentence])[0]).mean(0)\n",
    "        \n",
    "        \n",
    "get_representation =  lambda s: retrieval(s)[0][0]\n",
    "possible_negative_responses = ['So bad', 'I am sorry for you']\n",
    "possible_negative_representations = [get_representation(s) for s in possible_negative_responses]\n",
    "\n",
    "def square_rooted(x):\n",
    "    return round(np.sqrt(sum([a*a for a in x])),3)\n",
    "\n",
    "def cosine_similarity(x, y):\n",
    "    assert len(x) == len(y)\n",
    "    numerator = sum(a*b for a,b in zip(x,y))\n",
    "    denominator = square_rooted(x)*square_rooted(y)\n",
    "    return round(numerator/float(denominator),3)\n",
    "\n",
    "\n",
    "def retrieve_negative_response(ctx: Context, act: Actor, *args, **kwargs):\n",
    "    global possible_negative_responses, possible_negative_representations\n",
    "    request_encoding = get_representation(ctx.last_request)\n",
    "    #We look for the response vector whose cosine distance to the\n",
    "    response_index = np.argmax([cosine_similarity(request_encoding, negative_representation)\n",
    "                                for negative_representation in possible_negative_representations])\n",
    "    return possible_negative_responses[response_index]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_sentiment text\n",
      "get_sentiment text\n",
      "check text\n",
      "get_sentiment text\n",
      "check text\n",
      "get_sentiment text\n",
      "get_sentiment text\n",
      "get_sentiment text\n",
      "check text\n",
      "get_sentiment text\n",
      "check text\n",
      "get_sentiment text\n",
      "get_sentiment text\n",
      "get_sentiment text\n",
      "check text\n",
      "get_sentiment text\n",
      "check text\n",
      "get_sentiment text\n",
      "get_sentiment text\n",
      "get_sentiment text\n",
      "check text\n",
      "get_sentiment text\n",
      "check text\n",
      "get_sentiment text\n"
     ]
    }
   ],
   "source": [
    "def is_positive_condition(ctx: Context, act: Actor, *args, **kwargs):\n",
    "    print('check '+str(ctx.last_request))\n",
    "    return get_sentiment(ctx.last_request)=='POSITIVE' \n",
    "def is_negative_condition(ctx: Context, act: Actor, *args, **kwargs):\n",
    "    return get_sentiment(ctx.last_request)=='NEGATIVE' \n",
    "\n",
    "TRANSITION_LIST = {'node_negative' :is_negative_condition,\n",
    "                   'node_positive' :is_positive_condition} #the same transition list for all nodes\n",
    "\n",
    "\n",
    "script = {\n",
    "    \"flow\": {\n",
    "        \"node_start\": { # This is an initial node, it doesn't need a `RESPONSE`\n",
    "            RESPONSE: \"\",\n",
    "            TRANSITIONS: TRANSITION_LIST\n",
    "        }, \n",
    "        \"node_positive\": {\n",
    "            RESPONSE: \"Positive sentiment detected\", \n",
    "            TRANSITIONS: TRANSITION_LIST\n",
    "        },\n",
    "        \"node_negative\": {\n",
    "            RESPONSE: retrieve_negative_response,\n",
    "            TRANSITIONS: TRANSITION_LIST \n",
    "        },\n",
    "        \"node_fallback\": {RESPONSE: \"fallback node\", \n",
    "                          TRANSITIONS: TRANSITION_LIST} \n",
    "    }\n",
    "}\n",
    "\n",
    "actor = Actor(script, start_label=(\"flow\", \"node_start\"), fallback_label=(\"flow\", \"node_fallback\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using connector to write into file\n",
    "     \n",
    "We use connector to save the dialog state into json file. \n",
    "\n",
    "Note that this json file must not already exist. \n",
    "\n",
    "To make sure that it does not exist, we generate a unique dialog id to use in the file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIALOG_ID = str(random.randint(0, 100000))\n",
    "while os.path.exists(f\"file{DIALOG_ID}.json\"):\n",
    "    print(f'Dialog with id {DIALOG_ID} is already saved. Regenerating new dialog ID.')\n",
    "    DIALOG_ID = str(random.randint(0, 100000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we use the filename with this `DIALOG_ID` in the connector factory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "connector = connector_factory(f\"json://file{DIALOG_ID}.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " You can import any other connector using this factory, for example\n",
    "```\n",
    " connector = connector_factory(f\"pickle://file{DIALOG_ID}.pkl\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `turn_handler` saves data into the connector factory. The connector factory updates the json file every time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def turn_handler(in_request: str,\n",
    "                 actor: Actor,\n",
    "                 true_out_response: Optional[str] = None):\n",
    "    print('get from connector')\n",
    "    ctx = connector.get(USER_ID, Context(id=USER_ID))\n",
    "    print('work')\n",
    "    # Add in current context a next request of user\n",
    "    ctx.add_request(in_request)\n",
    "    # pass the context into actor and it returns updated context with actor response\n",
    "    ctx = actor(ctx)\n",
    "    #  breakpoint()\n",
    "    # get last actor response from the context\n",
    "    out_response = ctx.last_response\n",
    "    connector[USER_ID] = ctx\n",
    "    if true_out_response is not None and true_out_response != out_response:\n",
    "        msg = f\"in_request={in_request} -> true_out_response != out_response: {true_out_response} != {out_response}\"\n",
    "        raise Exception(msg)\n",
    "    else:\n",
    "        logging.info(f\"in_request={in_request} -> {out_response}\")\n",
    "    return out_response, ctx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTING_DIALOG=[('good', 'Positive sentiment detected'), ('bad', 'So bad')] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the function for running tests of the dialog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get from connector\n",
      "work\n",
      "get_sentiment good\n",
      "check good\n",
      "get_sentiment good\n",
      "get from connector\n",
      "work\n",
      "get_sentiment bad\n",
      "check bad\n",
      "get_sentiment bad\n"
     ]
    }
   ],
   "source": [
    "def run_test(mode=None):\n",
    "    ctx = {}\n",
    "    for in_request, true_out_response in TESTING_DIALOG:\n",
    "        _, ctx = turn_handler(in_request, actor, true_out_response=true_out_response)\n",
    "run_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the function for interacting with chatbot. This function repeatedly asks user for an input and gives this input to the turn_handler, which logs an output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactive mode\n",
    "def run_interactive_mode(actor):\n",
    "    ctx = {}\n",
    "    while True:\n",
    "        in_request = input(\"type your answer: \")\n",
    "        _, ctx = turn_handler(in_request, ctx, actor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here you can chat with your chatbot. Have fun!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "                                          \n",
    "if __name__ == \"__main__\":\n",
    "    logging.basicConfig(\n",
    "        format=\"%(asctime)s-%(name)15s:%(lineno)3s:%(funcName)20s():%(levelname)s - %(message)s\",\n",
    "        level=logging.INFO,\n",
    "    )\n",
    "    # run_test()\n",
    "    run_interactive_mode(actor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
